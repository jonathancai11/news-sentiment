{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NYT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nyt_1800.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    raw = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform from list of list to list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to use for-loops (can't vectorize) because there are None types in the data that we have to catch\n",
    "unzipped = list(zip(*raw))\n",
    "unzipped = unzipped[2]\n",
    "all_words = []\n",
    "for i in range(0, len(unzipped)):\n",
    "    str = ''\n",
    "    if (unzipped[i] is not None):\n",
    "        for j in range(0, len(unzipped[i])):\n",
    "            if (unzipped[i][j] is not None):\n",
    "                doc.append(unzipped[i][j])\n",
    "    all_words.append(\" \".join(doc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the TFIDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min_df means ignore terms that have a document frequency strictly lower than the given threshold. \n",
    "#Max_df is the opposite\n",
    "vectorizer = TfidfVectorizer(min_df=0.2, max_df = 0.8, sublinear_tf=True, use_idf =True, stop_words = 'english')\n",
    "train_corpus_tf_idf = vectorizer.fit_transform(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_corpus_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the matrix somewhere. May be needed in the future.\n",
    "scipy.sparse.save_npz('./sparse_matrix.npz', train_corpus_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try using the sparse matrix\n",
    "tfidf = train_corpus_tf_idf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  360,  4793],\n",
       "       [  360,  6956],\n",
       "       [  360, 16739],\n",
       "       ...,\n",
       "       [ 1799, 30229],\n",
       "       [ 1799, 30230],\n",
       "       [ 1799, 30231]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find locations in the matrix where values are non-zero\n",
    "np.transpose(np.nonzero(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3449470968681963"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[360, 4793]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the 100 most frequent words (may be useful later, if we don't use the scikit library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to use for-loops (can't vectorize) because there are None types in the data that we have to catch\n",
    "unzipped = list(zip(*raw))\n",
    "unzipped = unzipped[2]\n",
    "all_words = []\n",
    "for i in range(0, len(unzipped)):\n",
    "    if (unzipped[i] is not None):\n",
    "        for j in range(0, len(unzipped[i])):\n",
    "            if (unzipped[i][j] is not None):\n",
    "                all_words.append(unzipped[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011006"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All words are now in all words\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the          102911\n",
       "a             53025\n",
       "to            52305\n",
       "and           49524\n",
       "of            48976\n",
       "in            38593\n",
       "s             25565\n",
       "that          24370\n",
       "for           18869\n",
       "it            17702\n",
       "is            17653\n",
       "on            17325\n",
       "i             14474\n",
       "with          12769\n",
       "as            11291\n",
       "was           11243\n",
       "at            10695\n",
       "said           9757\n",
       "he             9393\n",
       "from           9067\n",
       "but            9018\n",
       "are            8843\n",
       "an             8711\n",
       "you            8420\n",
       "by             8418\n",
       "have           8118\n",
       "be             7941\n",
       "this           7390\n",
       "has            7260\n",
       "they           6991\n",
       "              ...  \n",
       "year           3294\n",
       "so             3286\n",
       "your           3255\n",
       "other          3170\n",
       "after          3047\n",
       "into           3030\n",
       "companies      2966\n",
       "time           2930\n",
       "could          2862\n",
       "over           2792\n",
       "them           2718\n",
       "do             2616\n",
       "york           2607\n",
       "times          2577\n",
       "just           2535\n",
       "two            2508\n",
       "first          2438\n",
       "years          2425\n",
       "most           2413\n",
       "no             2392\n",
       "m              2391\n",
       "trump          2388\n",
       "me             2343\n",
       "now            2325\n",
       "ms             2320\n",
       "tech           2274\n",
       "last           2266\n",
       "many           2214\n",
       "here           2180\n",
       "even           2090\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Start building the tfidf vector\n",
    "all_words = pd.Series(data = all_words)\n",
    "pd.Series(' '.join(all_words).lower().split()).value_counts()[:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
